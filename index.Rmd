---
title: "Development and Application of Machine Learning Techniques for Text Analyses and Classification in Clinical Research"
subtitle: '**Ph.D. course in: Traslational Specialistic Medicine "G.B. Morgagni"**'
author: "_Corrado Lanera_"
institute: "Department of Cardiac, Thoracic, Vascular Sciences, and Public Health<br>University of Padova"
date: "2020/03/17"
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: center, top, and title-slide
background-image: url("images/bg.png")
background-position: top
background-size: contain

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```


# Development and Application of<br>Machine Learning Techniques for<br>Analyses and Classification of Free-Text<br>in Clinical Research

**Corrado Lanera**

.left[
<br>
<br>
**Ph.D. course in:** Traslational Specialistic Medicine "G.B. Morgagni"<br>
**Curriculum:** Biostatistics<br>
**Supervisor:** Prof. Dario Gregori<br>
<br>
2020/03/17<br>
<br>
<br>
<br>
<br>
<br>
Department of Cardiac, Thoracic, Vascular Sciences, and Public Health<br>
University of Padova
]

???

Buongiorno a tutti e grazie per essere qui per la discusisone della mia
tesi di dottorato. Il tema trattato è quello dello sviluppo e dell'
applicazione di tecniche di auto apprendimento per l'analisi e la 
classificazione del testo in linguaggio naturale in ambito clinico.




















---
class: inverse, middle
# Outline

1. **Motivation:** _How can Free-Text analysis improve (help) clinical research?_

1. **Background 1:** _Natural Language Processing and Text Mining_

1. **Background 2:** _Machine Learning_

1. **Contributions:**

  - **Systematic Reviews**: _from `PubMed` to `ClinicalTrials.gov`_
  
  - **Emergency Departments' Visits**: _classification of discharge diagnoses_
  
  - **Electronic Health Records**:
    
      - _Case-detection of Varicella-Zoster Virus infections_
   
      - _Classification of otitis infections_

1. **Summary & Conclusion**

???

Comincerò dando alcune motivazioni e considerazioni che mi hanno spinto
e tuttora muovono i mie interessi in queste direzioni.

Dopodiché farò due brevi introduzioni per mostrare e fissare gli
strumenti che ho studiato e sfruttato nel corso di questi tre anni. 
Questo sia nel caso delle tecninche di autoapprendimento che quelle 
di analisi informatica del linguaggio naturale.

Quindi presenterò i lavori a cui ho dato maggiore contributo coi miei
studi su questi temi in questi tre anni insieme al nostro gruppo di
lavoro all'unità di biostatistica Epidemiologia e sanità pubblica.

Infine, vedremo quindi di ricapitolare in modo uniforme quanto fatto
cercando di fornire una panoramica uniforme a posteriori.



















---
class: center, middle, inverse
# Motivation

???

Iniziamo quindi con le motivazioni


---
class: center
background-image: url("images/clinical-texts.png")
background-position: bottom
background-size: contain

.pull-left[
### Documents' content
]

.pull-right[
### Clinical records
]

### Social-Media




???

La motivazione principale sta nell'aver osservato quanto il testo a 
linguaggio naturale sia diffuso nella pratica clinica. Medici,
infermieri, ricercatori e persino pazienti scambiano informnazioni
cliniche principalmente utilizzando il testo a linguaggio naturale.

Chiaramente ci sono tantissime misure rigorose e strutturate di
interesse clinico, come possono essere quelle numeriche, come per
esempio i livelli di emoglobina nel sangue o il peso, quelle categoriali,
come per esempio il sesso, o la classe NYHA, e così via.

Solo queste ultime però sono solitamente e riescono ad essere analizzate
in modo programamtico e strutturato, appunto. Tutti quei dati clinici
non strutturati come le immagini o il testo libero sono invece lasciate
alla sola ed esclusiva analisi "esperta" degli esseri umani, questo per 
la loro estrema complessità.

Pensiamo infatti anche solo a tutti gli articoli di ricerca o alle linee
guida, ai referti ospedalieri, i diari dei medici di base, alle note 
cliniche, ma anche ai messaggi sui social network delle persone che
esprimono disagi, possibili effetti avversi, usi e abusi di farmaci
e così via.

Il testo a linguaggio naturale, sopratutto e ancora, in ambito clinico
è praticamente esclusiva prerogativa del singolo medico o operatore che
lo legge.

- Guidelines
- Research papers
- Trials' protocols

- Discharge notes
- Clinical reports
- Family doctors' diaries

- General illness
- Adverse reactions
- Drugs (ab)use




















---
class: center, middle, inverse
# Background 1: Natural Language processing and Text Mining

???

Vediamo quindi innanzitutto come può ed è possibile analizzare 
il testo in linguaggio naturale per il recupero di informazioni non
banali da esso.

---
class: center

.pull-left[
# Search string

One or several strings (also called patterns) founded within a larger string or text.

<img src="images/MeSH-example.svg.png", width = 70%,  align = "center">
<small><small><small><small><small><small><small>
<https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/MeSH-example.svg/1024px-MeSH-example.svg.png>
</small></small></small></small></small></small></small>


<img src="images/Boolean_operations_on_shapes_a.png", width = 40%,  align = "center">
<img src="images/Boolean_operations_on_shapes_b.png", width = 40%,  align = "center">

<small><small><small><small><small>
<https://it.wikipedia.org/wiki/File:Boolean_operations_on_shapes.png>
</small></small></small></small></small>
]



.pull-right[
# Regular expressions

A sequence of characters that define a search pattern

<img src="images/crossword_regex.png",  align = "center">
<br><br>
<small><small><small>
<https://www.flickr.com/photos/bluesmoon/8458343489/in/photostream/>
</small></small></small>
]

???

La prima e intuitiva forma di ricerca è quella della semplice ricerca
delle parole nel testo. Questa pratica è stata in vari modi potenziata
sfruttanto l'utilizzo di parole chiave in vocabolari gerarchici, il 
cui più famoso forse in ambito medico sono la collezione dei termini 
MeSH usati dall abiblioteca nazionale di medicina americana per 
indicizzare tutti i lavori che colleziona.

Da questo è poi possibile usare la logica di insieme per unire,
intersecare, sottrarre e così via i risultati di singole ricerche.

Dall'altra parte uno strumento potentissimo che è stato sviluppato per 
il testo è il proto-linguaggio di programmazione delle espressioni
regolari che non sono altro che delle regole con cui scrivere istruzioni
per cercare il testo.

La differenza tra i due approcci è fondamentalmente quindi che nel primo
in modo più o meno complesso si definiscono e cercano le parole di
interesse, nel secondo si definiscono le regole da usare per la 
ricerca di qeuste parole.




---
class: middle

# Preprocessing

- **removing** (removes noise):
  - remove non-word text
  - remove stopwords
  - strip whitespace

- **merging** (reduces the risk to allow important information to become noise because they are dispersed):
  - lowering
  - stemming
  - lemmatization

- **producing** (from words to “tokens”, i.e. single indivisible piece of information to bring information which could be lost otherwise, e.g. negations):
  - n-Grams (consecutive sequences of n words)



???

A questo punto però dobbiamo riuscire a fare in modo di ottenere il
massimo delle informazioni possibili dal testo che stiamo analizzando
e quindi solutamente uno dei passagi più importanti è quello del 
pre processamento. 

Possiamo raccogliere i metodi di preprocessamento in tre grandi
categorie in base al loro effetto:

- la rimoszione di informazioni che possono confondere, come parole 
troppo comuni, o simboliche

- l'unione di parole in un'unica forma, come per esempio diverse
  declinazioni della stessa parola portate alla loro voce di
  vocabolario, che da multiple entità distinte a livello informatico
  divengono cosi una unica

- o la creazione di costrutti chiamati n-gram che non sono altro che
  sequenze contigue di n parole che vengono considerate a livello
  informatico come fossero una parola sola, pensiamo per esempio alle
  negazioni: se ogni parola fosse distinta e noi conoscessimo solo le
  singole parole (ipotizzando di non poter cogliere la sintassi di una
  frase) se non consideriamo una negazione come fosse una singola entità
  non potremmo coglierne nessuna.
  




---
class: middle

# Sparse representation

<img src="images/1_zFzLwr9kMiuT5FH9TPwd-Q.png", width = 80%  align = "center">

<small><small><small>
<https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c>
</small></small></small>



???

Bene, ora è necessario fare in modo di rappresentare le parole a livello
informatico per poter utilizzarle in un programma, il metodo classico è
quello di dare un indice a ogni parola e creare un dizionario di vettori
lunghi ciascuno quanto sono le parole in cui compaiono solo zeri tranne
nella cella corrispondente alla parola di interessa, che viene posta
a 1.

A questo punto possiamo rappresentare un documento con un vettore della
stessa lunghezza semplicemente sommando tutti i vettori delle parole che
lo compongono, ottenendo così una rappresentazione del documento con 
un vettore lungo tanto quanto il dizionario e in cui in ogni posizione
è riportata la frequenza con cui la parola corrispondente a quella
posizione compare nel documento.






---
class: middle

<img src="images/download.png",  align = "center">


???

Ora basta posizionare tutti questi vettori orizzontalmente uno sotto
l'altro per avere una rappresentazione matriciale a tabella di tutti
i nostri documenti in cui in una data cella, che corrisponde a una parola
in un docuemnto, è riportato quante volte tale parola compare in quel
dato documeto. 

Una volta ottenuta la raprpesentazione matriciale è poi possibile
trasformare questi valori per pesarli in funzione di una qualche misura 
di interesse che coinvolfa l'intera collezione.



Questa procedura però come è facile immaginare ha il vantagigo di essere
molto veloce e sempice da implementare ma ha due principali svantaggi:

- il primo è che gran parte dello spazio utilizzato è vuoto, ovvero 
composto da zeri. Abbiamo in fatti riservato a ogni docuemnto un vettore
lungo tanto quanto il numero di tutte le possibili parole mentre solo una 
piccolissima parte sarà stata utilizzata

- e secondo non cogliamo la relazione tra le parole che risultano quindi 
tutte completamente scorrelate una dall'altra



---
class: center, middle

<img src="images/skip-gram.png", width = 70%, align = "center">

<small><small><small><small>
.right[<https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/>]
</small></small></small>




???

Un modo completamente diverso e moderno invece si fonda sulla codifica
delle parole in in vettori "densi" ovvero composti interamente da cifre
non nulle, di dimensione molto minore della dimensione del vocabolario,
solitamente parliamo di vettori lunghi 300 celle contro anche le decine
di migliaia di celle o più della rtappresentazione one-hot.

Querste codfiche vengono auto apprese da reti neurali (che vedremo fra 
poco come funzionano) andando a modellare le parole in base al contesto
in cui si trovano, ovvero sfruttanto grandi basi di dati come può essere
per esempio tutto wikipedia nelle lingua di interesse.






---
class: center, middle

<img src="images/fasttext-example.png", align = "center">

<small><small><small><small>
.right[<https://www.tensorflow.org/images/linear-relationships.png>]
</small></small></small></small>




???

In questo modo ogni vettore rappresentante le coordinate di una parola
nbello spazio del linguaggio considerato che a questo punto aquista
delle proprietà lessico-geometriche arrivando a fenomeni che quello 
rappresentato, in cui, per esempio, se matematicamente dal vettore
rappresentatnre la parola re, togliamo il vettore rappresentante la
parola uomo e aggiungiamo il vettore per la parola donna, otteniamo
la parola regina.












---
class: center, middle, inverse
# Background 1: Machine Learning

???

vediamo quindi innanzitutto come un programma 

---
class: middle, center

<img src="images/ml-paradigm.png", align = "center">

Arthur Samuel (1959). **Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.**

???












---
class: middle, center

# (Shallow) Model definition
.pull-left[
Logistic regression 
<img src="images/Exam_pass_logistic_curve.jpeg", width = 65%,  align = "center">

<small><small><small><small>
<https://commons.wikimedia.org/wiki/File:Exam_pass_logistic_curve.jpeg>
</small></small></small></small>


k-nearest neighbor
<img src="images/KnnClassification.svg.png", width = 50%,  align = "center">

<small><small><small>
<https://it.m.wikipedia.org/wiki/File:KnnClassification.svg>
</small></small></small>
]


.pull-right[
support-vector machine
<img src="images/Kernel_Machine.png",  align = "center">

<small><small><small>
<https://commons.wikimedia.org/wiki/File:Kernel_Machine.png>
</small></small></small>

random forest (decision tree)
<img src="images/1_e18v-2-EabQTp_Bj92fkYA.png", width = 100%, align = "center">

<small><small><small><small><small><small>
<https://towardsdatascience.com/random-forests-and-decision-trees-from-scratch-in-python-3e4fa5ae4249>
]










---
class: center, middle

# (Artificial) Neuron

<img src="images/neuron.gif", width = 90%, align = "center">

<small><small><small><small>
.right[<https://www.cs.iusb.edu/~danav/teach/c463/12_nn.html>]
</small></small></small></small>

<br>
<big>
<big>
<big>
<big>
$=g(\sum(w_ia_i))$










---
class: center, middle

# Fully connect
<img src="images/fc.png", width = 70%, align = "center">

<small><small><small>
<https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/860px-Artificial_neural_network.svg.png>










---
class: top

# .center[(Deep-)Learning]

.center[Tom Mitchell (1998). **Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.**]

<img src="images/deep_gradient.png", align = "center">

.pull-left[
1. Random initialization
1. Forward propagation
1. Loss evaluation
1. Back propagation
1. Optimization and update
]


.pull-right[
<img src="images/Gradient_descent.gif", align = "center">
]
<small><small><small>.right[
<https://upload.wikimedia.org/wikipedia/commons/a/a3/Gradient_descent.gif>
]


















---
class: middle, inverse

# .cener[Contributions]

<small>
Lanera, C., Minto, C., Sharma, A., Gregori, D., Berchialla, P., & baldi, I. (2018). **Extending PubMed Searches to ClinicalTrials.gov Through a Machine Learning Approach for Systematic Reviews**.<br>
_Journal of Clinical Epidemiology._ <small>https://doi.org/10.1016/j.jclinepi.2018.06.015</small>


Lanera, C., Berchialla,  P., Sharma, A., Minto, C., Gregori, D., & Baldi, I. (2019). **Screening PubMed Abstracts: is Class Imbalance Always a Challenge to Machine Learning?**<br>
_BMC Systematic Reviews._ <small>https://doi.org/10.1186/s13643-019-1245-8</small>


Lorenzoni, G., Bressan, S., Lanera, C., Azzolina, D., Da Dalt, L., & Gregori, D. (2019). **Analysis of Unstructured Text-Based Data Using Machine Learning Techniques: The Case of Pediatric Emergency Department Records in Nicaragua.**<br>
_Medical Care Research and Review._ <small>https://doi.org/10.1177/1077558719844123</small>


Lanera, C., Berchialla, P., Baldi, I., Lorenzoni, G., Tramontan, L., Scamarcia, A., Cantarutti, L., Giaquinto, C., & Gre-gori, D. (2019). **Use of Machine Learning techniques for case-detection of Varicella Zoster using routinely collected textual ambulatory records.**<br>
_Journal of Medical Internet Research._ <small>https://www.ncbi.nlm.nih.gov/pubmed/management/validator/93DC7C7BE977/citations/</small>


Lanera, C., Barbieri, E., Piras, G., Lorenzoni, G., Maggie, A., Weissenbacher, D., Doná, D., Scamarcia, A., Cantarutti, L, Gonzalez, G., Giacquinto, C., &  Gregori, D. (2020). **Automatic identification and classification of different types of otitis from free-text pediatric medical notes: a deep-learning approach.**
(Preprint)
</small>


???

bar









---
class: center, middle, inverse
# Systematic Reviews

**Extending PubMed Searches to ClinicalTrials.gov Through a Machine Learning Approach for Systematic Reviews**

**Screening PubMed Abstracts: is Class Imbalance Always a Challenge to Machine Learning?**


---

## Motivation

- Searching not only through standard databases leads to
  - Increase of patients from 10% to 50%
  - Change in statistics from 0% to 29%

<img src="images/BMJ17.PNG", width = 80%,  align = "right">

<br>
<br>
<br>
<br>
<br>
<br>

- Despite their relevant role, clinical trial registries are under-utilized
  - No hierarchical branching structure
  - Text search is based on few fields
  - Cannot use queries’ combination

<img src="images/UnderUse17.PNG", width = 80%,  align = "right">









---

## Methods

14 Systematic reviews and Meta-analyses re-analyzed by 
Baudard et al.*

- Training (PubMED):
 - Positive : trials originally included in the systematic reviews
 - Negative: off topic trials randomly choosen (1/20)
- Test (ClinicalTrial.gov):
 - Positive : trials by Baudard et al. study
 - Negative: off topic trials randomly choosed (up to a set of 100)

<img src="images/selection.PNG", width = "55%"  align = "right">


- MLT (10-fold Cross-Validation):
 - GLM Net
 - k-NN
 - Random Forests
 - **Support-Vector Machine**


- Balancing methods:
 - Random Under-sampling
 - Random Over-sampling
 - 50:50
 - **35:65**

<small><small><small>Baudard M, Yavchitz A, Ravaud P, et al. **Impact of searching clinical trial registries in systematic reviews of pharmaceutical treatments: methodological systematic review and reanalysis of meta-analyses.** _BMJ_ (2017).</small></small></small>




???
Routine examination of registry databases deserves further
consideration since it may allow a more characterization of
publication and outcome reporting biases and improve the
validity of Systematic Reviews
The approach described here provides an automated solution
that can be tailored to address a variety of Clinical Trial-related
questions by building a comprehensive search on both literature
and registry databases.

---
class: center

<img src="images/Flowchart.jpg", width = "75%">


---
class: center

#### SVM performances

ID | review       | manual |   mlt | delta     |   pos |  sens
--:| -------------|-------:|------:|----------:|------:|:------:
 1 | Yang Q       |     12 |   457 |    -445   |    18 |  1    
 2 | Meng Y       |     26 |   144 |    -118   |     9 |  1    
 3 | Segelov E    |    684 |   274 |     410   |    13 |  **0.875**
 4 | Li DH        |    201 |   289 |     -88   |     6 |  1    
 5 | Lv ZC        |    665 |   243 |     422   |    12 |  1    
 6 | Wang J       |    227 |   729 |    -502   |    32 |  1    
 7 | Zhou CQ      |      3 |   263 |    -260   |     9 |  1    
 8 | Liu X        |   1661 |   622 |  **1039** |    23 |  1    
 9 | Douxfils J   |     76 |   116 |     -40   |    13 |  1    
10 | Kourbeti IS  |    581 |   409 |     172   |    75 |  1    
11 | Li EC        |    909 |  2119 | **-1210** |     9 |  1    
12 | Cavender MA  |     71 |    60 |      11   |    14 |  1    
13 | Chatterjee S |    217 |   169 |      48   |    18 |  1    
14 | Funakoshi T  |   2680 |   711 |  **1969** |    43 |  1    






---
class: center, middle

<img src="images/rf-meta.jpg">




---
class: center, middle, inverse
# Emergency Departments Visits

**Analysis of Unstructured Text-Based Data Using Machine Learning Techniques: The Case of Pediatric Emergency Department Records in Nicaragua.**
---

## Motivation


<img src = "images/ambulance.png">

- Multi-source Multi-format Clinical Data

- Small dataset


???

ITALY-NICARAGUA COOPERATION PROGRAM

Started in 2011 
Italian and Nicaraguan pediatricians

AIMS
- Setting up a pediatric emergency clinical network in Nicaragua
- Improving Nicaraguan pediatric Emergency Care

DATA COLLECTION
established an electronic data collection system
9 Nicaraguan hospitals



---
class: center, middle

<img src = "images/nicaragua.png">

???

bar








---
class: center, middle, inverse
# Electronic Health Records

**Use of Machine Learning techniques for case-detection of Varicella Zoster using routinely collected textual ambulatory records.**

**Automatic identification and classification of different types of otitis from free-text pediatric medical notes: a deep-learning approach.**












---

<img src="images/barbieri2019.png", width = "32%", align = "right">

<big><big>

2019 <img src="images/logopedianet.png", width = "20%", align = "center"> investigation

- data from 2010 to 2015 

- **on primary diagnosis only**

Adding the diaries in a traditional manual human-driven analysis proved to be 
**too costly** in terms both of person-time and economic resources


It is necessary to develop an **accurate** system able to **automatically**
classify all the <img src="images/logopedianet.png", width = "15%", align = "center"> records by investigating **all the textual fields** in the database.

<small><small><small><small><small><small>\*Barbieri et.al "Antibiotic prescriptions in acute otitis media and pharyngitis in Italian pediatric outpatients", **Italian J. of Pediatrics** 2019</small></small></small></small></small></small>


???

- Otitis media is one of the **most common infections in pediatrics**
  population.

- It is an **inflamamtion with possible fluid accumulation** in the
  middle ear

- and there is continuing interest in defining the incidence and the
  burden of acute cases, being one of the main cause of antibiotics
  prescriptions in children.
  
- This is also highlighted by the **chellenges in the diagnoses** and by 
the **frequently little attention in following the guidlines**, like the
**wait-and-see approach** that discourage early antibiotics prescription,
reducing their usage and the adverse events associated with that.

Pedianet was investigated in 2019 by Barbieri et.al\* on data from 
2010 to 2015 for similar task **on primary diagnosis only**: adding even
the diaries in a traditional manual human-driven analysis proved to be 
too costly in terms both of person-time (years) and economic resources

It is necessary to develop an **accurate** system able to classify all
the Pedianet records **automatically** investigating **all the textual
fields** in the database.



---

## First Study on <img src="images/logopedianet.png", width = "30%", align = "center"> 

Aim: **comparing Machine Learning Techniques with application to Electronic Healt Records analysis for disease detection.**

Two distinct Italian regions’ <img src="images/logopedianet.png", width = "20%", align = "center"> dataset collected between 2004 and 2014 in:
<img src = "images/varicella-1_diagram.png",  width = "38%", align = "right">

- Veneto (training):
  - 7,631 patients 1,230,355 records
- Sicilia (test):
  - 2,347 patients and 569,926 records
  

- Records included dichotomous labels:
  - **non-case**
  - **case**


Technique	|     Accuracy	    |         F
----------|-------------------|-----------------
GLMNet  	| 86.6 (84.6–88.7)	| 36.5 (32.2–40.8)
MAXENT	  | 66.0 (56.4–75.5)	| 19.1 (17.2–20.9)
Boosting	| 96.0 (93.8–98.1)	| 68.5 (59.3–77.7)


???

bar

---
class: middle

<img src="images/flowchart_otiti.png", width = "52%", align = "right">

#### Data

2004/01/01 to 2017/08/23
- 144 pediatricians
- 216,976 children


#### Classification task

<ol start="0">
<li><strong>other</strong> than an otitis case</li><br>
<li>an otitis case which is <strong>not media</strong></li><br>
<li>a media otitis which is <strong>not acute</strong></li><br>
<li><img src="images/aom.jpg", width = "10%", align = "left">
  an AOM (<strong>w/o</strong> tympanic membrane perforation, nor recurrent)</li><br>
  
<li><img src="images/aom_perforation.jpg", width = "10%", align = "left">
  an AOM with tympanic <strong>membrane perforation</strong></li><br><br>
<li>a <strong>recurrent</strong> AOM</li>
</ol>


.pull-right[
.footnote[<small><small><small><small>http://otitismedia.hawkelibrary.com</small></small></small></small>]
]

---
class: center, middle

Network                            |  Accuracy | Balanced<br>F1
-----------------------------------|  :------: | :------------:
**Annotator A**                    |   95.91   |      93.47 
**Annotator B**                    |   95.80   |      90.12 
**(Annotators' average)**          |  (95.86)  |     (91.80)
Simple Embedding                   |   81.70   |      75.75
Single Kernel                      |   94.66   |      92.23
Sequential CNN                     |   93.64   |      87.99
Parallel CNN                       | **96.59** |    **95.86**
Deep CNN                           | **96.25** |    **94.85**
Ensemble<br>(w/o Simple Embeddings)| **96.59** |    **95.47**

.pull-right[
  \* **Bold face** = over the annotators' maximum <br>
]
















---
class: center, middle, inverse
# Summary & Conclusion

---
class: middle

<img src="images/3mt.png", align = "center">

???

bar




















---
class: center, middle, inverse
<br>
<br>
<br>
<br>
<br>
<br>

# **Thank you<br>for the attention**

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

<small><small><small>Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan) powered by [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).
